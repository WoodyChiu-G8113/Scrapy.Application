# Scrapy.Application

1. 使用 Python，因為我是新手所以盡可能分步驟執行
2. 使用 Python 建立 API入口
3. 每次調整都回寫 prd.txt
4. 使用 uv 管理套件
5. 範例僅參考還是依照**工作一**要做的事情

## 範例

# 參考範例

```
Step01: 下載原始資料
Step02: 將資料載入程式：document_loaders
Step03: 索引存入資料庫：VectorstoreIndexCreator
Step04: 連接資料庫：Chroma
Step05: 對話查詢：create_retrieval_chain
```

# 參考範例原始碼

Step01: 下載原始資料

```
## Step01: 下載原始資料

!mkdir "旅遊"
!curl -L "https://ppt.cc/fTdnwx" -e "https://ppt.cc/fTdnwx" -o "旅遊/nt.pdf"
!ls
```

```
!pip install pypdf
```

```
## Step02: 將資料載入程式：document_loaders

from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("./旅遊/nt.pdf")
pages = loader.load_and_split()
pages[0]

```

```
## Step03: 向量化索引存入資料庫：VectorstoreIndexCreator
# 文本 -> 向量化 -> 分割/索引 -> 建立資料庫 -> 存檔

from langchain.vectorstores import Chroma
from langchain.indexes import VectorstoreIndexCreator
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
index_creator = VectorstoreIndexCreator(
            embedding=embeddings,
            vectorstore_cls=Chroma,
            vectorstore_kwargs={"persist_directory":"./vector"}
)
docsearch = index_creator.from_loaders([loader])
docsearch.vectorstore.persist()
docsearch
```

```
## Step04: 連接資料庫：Chroma


db = Chroma(persist_directory='./vector', embedding_function=embeddings)
db
```

```
## Step05: 對話查詢：RetrievalQA -> create_retrieval_chain (RAG)

from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

retriever = db.as_retriever(search_kwargs={"k":2})

from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=OPENAI_API_KEY)

# from langchain_google_genai import ChatGoogleGenerativeAI
# llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=GEMINI_API_KEY)

system_prompt = (
    "Use the given context to answer the question. "
    "If you don't know the answer, say you don't know. "
    "Use three sentence maximum and keep the answer concise. "
    "請根據上下文來回答問題，不知道答案就回答不知道不要試圖編造答案"
    "你是一位旅遊助理，請根據景點資訊回覆使用者的問題"
    "Context: {context}"
)
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}"),
    ]
)
question_answer_chain = create_stuff_documents_chain(llm, prompt)
chain = create_retrieval_chain(retriever, question_answer_chain)
# retriever = 資料從哪裡來？ = {context}
# question_answer_chain = 你要怎麼查資料？
chain
```

## 简介

**工作一**：
幫我依照上面的 Google Colab 範例，使用 Python 撰寫一個 RAG 的應用程式。

1. 取得 PFD 內容 使用 Python 讀取 PDF (114news_Q1.pdf) `from langchain.document_loaders import PyPDFLoader`
2. 切字
   切字工具
   https://github.com/ckiplab/ckip-transformers?tab=readme-ov-file

3. Rag 資料庫選用 先使用 Chroma

4. 不需要撰寫測試案例

5. 使用 uv 管理套件

---